{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f409d66",
   "metadata": {},
   "source": [
    "# Kindle Review Sentiment Analysis\n",
    "This notebook demonstrates sentiment analysis on Amazon Kindle reviews using multiple feature extraction methods: Bag of Words, TF-IDF, and Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451db53",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "Load the dataset and check for missing values and rating distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6337a5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "data=pd.read_csv('kindle_review_dataset/all_kindle_review.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7890897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3\n",
       "1  Great short read.  I didn't want to put it dow...       5\n",
       "2  I'll start by saying this is the first of four...       3\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4  I did not expect this type of book to be in li...       4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data[['reviewText','rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15ea1daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a1fc1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72714bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "981f3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "255fc91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\3939683566.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rating']=df['rating'].apply(lambda x:0 if x<3 else 1)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing And Cleaning\n",
    "## postive review is 1 and negative review is 0\n",
    "df['rating']=df['rating'].apply(lambda x:0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "850822df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a004406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\1654308119.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "## 1. Lower All the cases\n",
    "df['reviewText']=df['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ed3399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may be short, but he's nothing to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read.  i didn't want to put it dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'll start by saying this is the first of four...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie is angela lansbury who carries pocketboo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i did not expect this type of book to be in li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may be short, but he's nothing to ...       1\n",
       "1  great short read.  i didn't want to put it dow...       1\n",
       "2  i'll start by saying this is the first of four...       1\n",
       "3  aggie is angela lansbury who carries pocketboo...       1\n",
       "4  i did not expect this type of book to be in li...       1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c007e279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f887e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b86afdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\asus\\onedrive\\desktop\\python\\venv\\lib\\site-packages (6.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3723fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x:re.sub('[^a-z A-z 0-9-]+', '',x))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(x)))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(x)))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x: \" \".join(x.split()))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\649204663.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x: \" \".join(x.split()))\n"
     ]
    }
   ],
   "source": [
    "## Removing special characters\n",
    "df['reviewText']=df['reviewText'].apply(lambda x:re.sub('[^a-z A-z 0-9-]+', '',x))\n",
    "## Remove the stopswords\n",
    "df['reviewText']=df['reviewText'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
    "## Remove url \n",
    "df['reviewText']=df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(x)))\n",
    "## Remove html tags using BeautifulSoup with 'html.parser' instead of 'lxml'\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "## Remove any additional spaces\n",
    "df['reviewText']=df['reviewText'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21f075c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short hes nothing mess man hau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sitti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start saying first four books wasnt expect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carries pocketbooks inst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library pleased find price right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may short hes nothing mess man hau...       1\n",
       "1  great short read didnt want put read one sitti...       1\n",
       "2  ill start saying first four books wasnt expect...       1\n",
       "3  aggie angela lansbury carries pocketbooks inst...       1\n",
       "4  expect type book library pleased find price right       1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30eb79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5a322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5921b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51f19830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24616\\1959687590.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x:lemmatize_words(x))\n"
     ]
    }
   ],
   "source": [
    "df['reviewText']=df['reviewText'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4cb3600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short he nothing mess man haul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sitti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start saying first four book wasnt expecti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carry pocketbook instead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library pleased find price right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may short he nothing mess man haul...       1\n",
       "1  great short read didnt want put read one sitti...       1\n",
       "2  ill start saying first four book wasnt expecti...       1\n",
       "3  aggie angela lansbury carry pocketbook instead...       1\n",
       "4  expect type book library pleased find price right       1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f864f",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Cleaning\n",
    "Lowercase, remove special characters, stopwords, URLs, HTML tags, and extra spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8001482",
   "metadata": {},
   "source": [
    "## 3. Lemmatization\n",
    "Apply lemmatization to normalize words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabb249",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split\n",
    "Split the cleaned reviews and binary ratings into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f61ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['reviewText'],df['rating'],\n",
    "                                              test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273faa23",
   "metadata": {},
   "source": [
    "## 5. Bag of Words Feature Extraction\n",
    "Convert text to numerical features using Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "488aa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow=CountVectorizer()\n",
    "X_train_bow=bow.fit_transform(X_train)\n",
    "X_test_bow=bow.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037d079",
   "metadata": {},
   "source": [
    "## 6. TF-IDF Feature Extraction\n",
    "Convert text to numerical features using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1345db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0526c5",
   "metadata": {},
   "source": [
    "## 7. Train Multinomial Naive Bayes Classifier\n",
    "Train and evaluate on BOW and TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9dbaefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Use MultinomialNB for sparse/dense high-dimensional text data to avoid MemoryError\n",
    "nb_model_bow = MultinomialNB().fit(X_train_bow, y_train)\n",
    "nb_model_tfidf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1291dae",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation: BOW and TF-IDF\n",
    "Evaluate accuracy and print confusion matrix for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84283fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce18d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW accuracy:  0.8325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       849\n",
      "           1       0.85      0.90      0.87      1551\n",
      "\n",
      "    accuracy                           0.83      2400\n",
      "   macro avg       0.82      0.80      0.81      2400\n",
      "weighted avg       0.83      0.83      0.83      2400\n",
      "\n",
      "BOW Confusion Matrix:\n",
      " [[ 595  254]\n",
      " [ 148 1403]]\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate BOW model\n",
    "y_pred_bow = nb_model_bow.predict(X_test_bow)\n",
    "print(\"BOW accuracy: \", accuracy_score(y_test, y_pred_bow))\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "print(\"BOW Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a32fe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF accuracy:  0.6708333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13       849\n",
      "           1       0.66      1.00      0.80      1551\n",
      "\n",
      "    accuracy                           0.67      2400\n",
      "   macro avg       0.83      0.53      0.46      2400\n",
      "weighted avg       0.78      0.67      0.56      2400\n",
      "\n",
      "TFIDF Confusion Matrix:\n",
      " [[  59  790]\n",
      " [   0 1551]]\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate TFIDF model\n",
    "y_pred_tfidf = nb_model_tfidf.predict(X_test_tfidf)\n",
    "print(\"TFIDF accuracy: \", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print(\"TFIDF Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b9242",
   "metadata": {},
   "source": [
    "## 9. Word2Vec Feature Extraction\n",
    "Train Word2Vec model and use average word vectors for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8c9a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize reviews for Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "reviews_tokenized = [simple_preprocess(text) for text in df['reviewText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba60a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(sentences=reviews_tokenized, vector_size=100, window=5, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8440dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get average word2vec for a review\n",
    "import numpy as np\n",
    "def avg_word2vec(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv.index_to_key]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2faba10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average word2vec for all reviews\n",
    "X_word2vec = np.vstack([avg_word2vec(tokens, w2v_model) for tokens in reviews_tokenized])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d0ef6",
   "metadata": {},
   "source": [
    "## 10. Train-Test Split for Word2Vec Features\n",
    "Split the Word2Vec features and labels for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a37f6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_word2vec, df['rating'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65a535",
   "metadata": {},
   "source": [
    "## 11. Random Forest Classifier on Word2Vec Features\n",
    "Train and evaluate RandomForest on average Word2Vec features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "665997fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec (Avg) accuracy:  0.7666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.60       760\n",
      "           1       0.80      0.87      0.84      1640\n",
      "\n",
      "    accuracy                           0.77      2400\n",
      "   macro avg       0.73      0.71      0.72      2400\n",
      "weighted avg       0.76      0.77      0.76      2400\n",
      "\n",
      "Word2Vec Confusion Matrix:\n",
      " [[ 413  347]\n",
      " [ 213 1427]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model_w2v = RandomForestClassifier()\n",
    "rf_model_w2v.fit(X_train_w2v, y_train_w2v)\n",
    "y_pred_w2v = rf_model_w2v.predict(X_test_w2v)\n",
    "print(\"Word2Vec (Avg) accuracy: \", accuracy_score(y_test_w2v, y_pred_w2v))\n",
    "print(classification_report(y_test_w2v, y_pred_w2v))\n",
    "print(\"Word2Vec Confusion Matrix:\\n\", confusion_matrix(y_test_w2v, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd994f8",
   "metadata": {},
   "source": [
    "## 12. Accuracy Matrix Comparison\n",
    "Compare all methods (BOW, TFIDF, AvgWord2Vec) on accuracy and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc3554e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Matrix (All Methods):\n",
      "              accuracy        f1\n",
      "BOW          0.832500  0.874688\n",
      "TFIDF        0.670833  0.797020\n",
      "AvgWord2Vec  0.766667  0.835970\n"
     ]
    }
   ],
   "source": [
    "# Collect accuracy and F1-score for all methods\n",
    "from sklearn.metrics import f1_score\n",
    "results = {\n",
    "    'BOW': {\n",
    "        'accuracy': accuracy_score(y_test, y_pred_bow),\n",
    "        'f1': f1_score(y_test, y_pred_bow)\n",
    "    },\n",
    "    'TFIDF': {\n",
    "        'accuracy': accuracy_score(y_test, y_pred_tfidf),\n",
    "        'f1': f1_score(y_test, y_pred_tfidf)\n",
    "    },\n",
    "    'AvgWord2Vec': {\n",
    "        'accuracy': accuracy_score(y_test_w2v, y_pred_w2v),\n",
    "        'f1': f1_score(y_test_w2v, y_pred_w2v)\n",
    "    }\n",
    "}\n",
    "import pandas as pd\n",
    "accuracy_matrix = pd.DataFrame(results).T\n",
    "print(\"\\nAccuracy Matrix (All Methods):\\n\", accuracy_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
